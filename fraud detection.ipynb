{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b6a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Credit-Card-Fraud-Detection'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Sarah627/Credit-Card-Fraud-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd104bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e6c6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\ahmed\\Credit-Card-Fraud-Detection\\cleansed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77891d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.692570</td>\n",
       "      <td>0.684420</td>\n",
       "      <td>-0.681072</td>\n",
       "      <td>0.661313</td>\n",
       "      <td>-0.956476</td>\n",
       "      <td>0.132650</td>\n",
       "      <td>0.162292</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>-0.037786</td>\n",
       "      <td>0.116353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132785</td>\n",
       "      <td>-0.130266</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.470278</td>\n",
       "      <td>0.074176</td>\n",
       "      <td>-1.042174</td>\n",
       "      <td>-0.050446</td>\n",
       "      <td>-0.045423</td>\n",
       "      <td>-0.334524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.271345</td>\n",
       "      <td>0.157499</td>\n",
       "      <td>-0.634418</td>\n",
       "      <td>-0.055032</td>\n",
       "      <td>1.255515</td>\n",
       "      <td>-0.425593</td>\n",
       "      <td>0.997861</td>\n",
       "      <td>0.783638</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>-1.102214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309792</td>\n",
       "      <td>0.521508</td>\n",
       "      <td>1.952374</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>0.742493</td>\n",
       "      <td>1.105254</td>\n",
       "      <td>-0.202731</td>\n",
       "      <td>-0.095967</td>\n",
       "      <td>3.822321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.752553</td>\n",
       "      <td>-0.221098</td>\n",
       "      <td>0.269237</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>-1.026833</td>\n",
       "      <td>0.280679</td>\n",
       "      <td>0.148012</td>\n",
       "      <td>0.316023</td>\n",
       "      <td>-0.218214</td>\n",
       "      <td>0.189374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800190</td>\n",
       "      <td>-0.182205</td>\n",
       "      <td>-0.258031</td>\n",
       "      <td>-0.886093</td>\n",
       "      <td>1.945438</td>\n",
       "      <td>-0.037087</td>\n",
       "      <td>-0.310553</td>\n",
       "      <td>-0.401827</td>\n",
       "      <td>-0.344800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.011078</td>\n",
       "      <td>0.493430</td>\n",
       "      <td>-0.263709</td>\n",
       "      <td>-0.186122</td>\n",
       "      <td>0.256494</td>\n",
       "      <td>-0.080800</td>\n",
       "      <td>-0.219538</td>\n",
       "      <td>0.294556</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.080358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190881</td>\n",
       "      <td>0.884429</td>\n",
       "      <td>0.873441</td>\n",
       "      <td>1.715494</td>\n",
       "      <td>-0.744589</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.105638</td>\n",
       "      <td>-0.138772</td>\n",
       "      <td>1.045192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.648476</td>\n",
       "      <td>0.821269</td>\n",
       "      <td>-0.478579</td>\n",
       "      <td>0.173912</td>\n",
       "      <td>-0.449114</td>\n",
       "      <td>0.672798</td>\n",
       "      <td>0.199015</td>\n",
       "      <td>0.594452</td>\n",
       "      <td>-0.115222</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092216</td>\n",
       "      <td>0.283036</td>\n",
       "      <td>-0.184909</td>\n",
       "      <td>-2.491057</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>-0.909566</td>\n",
       "      <td>-0.111027</td>\n",
       "      <td>-0.250955</td>\n",
       "      <td>-0.222291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -0.692570  0.684420 -0.681072  0.661313 -0.956476  0.132650  0.162292   \n",
       "1  1.271345  0.157499 -0.634418 -0.055032  1.255515 -0.425593  0.997861   \n",
       "2  0.752553 -0.221098  0.269237  0.306200 -1.026833  0.280679  0.148012   \n",
       "3  1.011078  0.493430 -0.263709 -0.186122  0.256494 -0.080800 -0.219538   \n",
       "4  0.648476  0.821269 -0.478579  0.173912 -0.449114  0.672798  0.199015   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.345529 -0.037786  0.116353  ... -0.132785 -0.130266  0.156352  0.470278   \n",
       "1  0.783638  0.041772 -1.102214  ...  0.309792  0.521508  1.952374 -0.022174   \n",
       "2  0.316023 -0.218214  0.189374  ...  0.800190 -0.182205 -0.258031 -0.886093   \n",
       "3  0.294556  0.056499  0.080358  ...  0.190881  0.884429  0.873441  1.715494   \n",
       "4  0.594452 -0.115222  0.412175  ... -0.092216  0.283036 -0.184909 -2.491057   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.074176 -1.042174 -0.050446 -0.045423 -0.334524      0  \n",
       "1  0.742493  1.105254 -0.202731 -0.095967  3.822321      1  \n",
       "2  1.945438 -0.037087 -0.310553 -0.401827 -0.344800      0  \n",
       "3 -0.744589  0.373816  0.105638 -0.138772  1.045192      1  \n",
       "4  0.834222 -0.909566 -0.111027 -0.250955 -0.222291      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa772e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Time        V1        V2        V3        V4        V5        V6  \\\n",
      "1    1.271345  0.157499 -0.634418 -0.055032  1.255515 -0.425593  0.997861   \n",
      "3    1.011078  0.493430 -0.263709 -0.186122  0.256494 -0.080800 -0.219538   \n",
      "6   -1.430992 -2.353613  1.533878 -2.490417  2.804992 -1.260919 -0.819810   \n",
      "8   -0.036072 -0.095959  0.054684  0.480650  0.253219 -0.050459  0.499552   \n",
      "14  -0.405513  0.312936 -0.534543  0.531705 -1.128157 -0.080589  0.770698   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "972  1.186107 -0.506308 -0.421749 -0.308604  0.042227  0.533933 -0.751871   \n",
      "973  0.749112  0.086178 -2.491779 -0.090482 -0.301469 -0.117554  0.304698   \n",
      "978 -1.664678  0.508720  0.525976 -0.341147  1.191842  0.736497 -1.114748   \n",
      "979 -0.958669 -1.086204  1.169410 -1.313648  1.398395 -1.559302 -1.706891   \n",
      "980  1.687507  0.200748  0.246465 -0.137852  0.042447 -0.030150  0.421334   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "1    0.783638  0.041772 -1.102214  ...  0.309792  0.521508  1.952374   \n",
      "3    0.294556  0.056499  0.080358  ...  0.190881  0.884429  0.873441   \n",
      "6   -2.065699 -0.202176 -2.546319  ... -1.003268  0.616047 -0.285140   \n",
      "8   -0.267500 -0.549773  0.132626  ... -0.075044  1.056910 -0.219789   \n",
      "14   0.989793 -0.153677  0.826580  ... -0.118220  0.335040  0.074469   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "972 -0.523481 -0.236140 -0.665042  ... -0.364033  0.432088 -0.944340   \n",
      "973  0.957207 -0.203455  1.191070  ...  0.309331 -0.866727 -1.539749   \n",
      "978  0.341077 -0.043742 -0.600293  ... -0.059083 -0.438343 -0.490867   \n",
      "979 -1.639955  1.092501 -2.138221  ...  0.646830 -0.243375  0.019179   \n",
      "980  0.311268 -0.493573 -0.318455  ... -0.443205  0.426612  0.131141   \n",
      "\n",
      "          V24       V25       V26       V27       V28    Amount  Class  \n",
      "1   -0.022174  0.742493  1.105254 -0.202731 -0.095967  3.822321      1  \n",
      "3    1.715494 -0.744589  0.373816  0.105638 -0.138772  1.045192      1  \n",
      "6   -1.666965  1.427739  1.683566  2.130375 -2.665236 -0.421683      1  \n",
      "8    1.061355 -0.397380 -0.156368  0.377781 -0.148087 -0.417419      1  \n",
      "14  -0.338646  0.775822 -1.167126  0.076218 -0.331927  1.915340      1  \n",
      "..        ...       ...       ...       ...       ...       ...    ...  \n",
      "972  0.418070  0.264499 -1.500659  0.494259 -0.456166 -0.387997      1  \n",
      "973  1.277780 -0.719861 -1.909456 -0.456848  0.616863  8.639131      1  \n",
      "978 -0.298353  2.147385  0.999993  0.434337  0.810989 -0.421683      1  \n",
      "979  0.822008 -0.094248  1.066193  0.700618  0.074792 -0.296914      1  \n",
      "980  0.758089  0.088747 -0.901007  0.372210  0.138400  1.062590      1  \n",
      "\n",
      "[492 rows x 31 columns]\n",
      "         Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0   -0.692570  0.684420 -0.681072  0.661313 -0.956476  0.132650  0.162292   \n",
      "2    0.752553 -0.221098  0.269237  0.306200 -1.026833  0.280679  0.148012   \n",
      "4    0.648476  0.821269 -0.478579  0.173912 -0.449114  0.672798  0.199015   \n",
      "5   -0.457583  0.104322 -0.728718  0.876795 -0.615333  0.804438  0.041071   \n",
      "7   -0.119589  0.238538 -0.177221  0.676908 -0.201455  0.165823  0.039378   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "976  1.208575  0.259059 -0.447877  0.251380 -0.425474  0.536961  0.420670   \n",
      "977 -0.386716  0.669787 -0.803879  0.660602 -0.944591  0.089652  0.398838   \n",
      "981 -1.052193  0.348786 -0.310831  0.689597 -0.375999  0.225143  0.400298   \n",
      "982 -1.775112  0.655427 -0.461149  0.644174 -0.299376  0.335236  0.375653   \n",
      "983  0.744098  0.083760 -1.089501  0.665974 -0.952129 -0.045753  0.795325   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "0    0.345529 -0.037786  0.116353  ... -0.132785 -0.130266  0.156352   \n",
      "2    0.316023 -0.218214  0.189374  ...  0.800190 -0.182205 -0.258031   \n",
      "4    0.594452 -0.115222  0.412175  ... -0.092216  0.283036 -0.184909   \n",
      "5    0.453342 -0.047383  0.610372  ... -0.141585  0.023712 -0.375048   \n",
      "7    0.435612  0.089855  0.179233  ...  0.007180  0.734849 -0.138660   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "976  0.938260 -0.068763 -0.491184  ...  0.069058  0.594588  0.578556   \n",
      "977  0.293867 -0.033119  0.421349  ...  0.016815  0.844237 -0.169764   \n",
      "981  0.528284  0.070561  0.196890  ... -0.050859  0.271351  0.292341   \n",
      "982  0.466811 -0.036385  0.535348  ... -0.146022  0.114588 -0.030088   \n",
      "983  0.879428 -0.067325  0.609472  ... -0.033215 -0.598643  1.444275   \n",
      "\n",
      "          V24       V25       V26       V27       V28    Amount  Class  \n",
      "0    0.470278  0.074176 -1.042174 -0.050446 -0.045423 -0.334524      0  \n",
      "2   -0.886093  1.945438 -0.037087 -0.310553 -0.401827 -0.344800      0  \n",
      "4   -2.491057  0.834222 -0.909566 -0.111027 -0.250955 -0.222291      0  \n",
      "5   -0.520828  1.151049 -0.832506 -0.351737 -0.043292 -0.375460      0  \n",
      "7    0.842026 -0.276525 -0.115469 -0.243334 -0.129949 -0.239262      0  \n",
      "..        ...       ...       ...       ...       ...       ...    ...  \n",
      "976  0.338722 -0.285588  5.183586 -0.385546  0.130763  1.339975      0  \n",
      "977 -0.647607  0.506562 -0.020202 -0.036796 -0.005163 -0.003794      0  \n",
      "981  0.404398 -0.684244 -0.918525 -0.135372 -0.116456  0.054497      0  \n",
      "982  0.536713  0.871333 -0.751752 -0.030399 -0.057691 -0.421683      0  \n",
      "983  0.970285  0.452280  1.216325 -0.330961  0.217733  2.772183      0  \n",
      "\n",
      "[492 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "fraudData = dataset[dataset['Class'] == 1]\n",
    "nonFraudData = dataset[dataset['Class'] == 0]\n",
    "print(fraudData)\n",
    "print(nonFraudData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "405fc692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6c7bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_data):\n",
    "    model=models.Sequential([\n",
    "        #first layer\n",
    "        layers.Dense(128, activation = 'relu', input_dim = input_data), \n",
    "        layers.Dense(256, activation = 'relu'),\n",
    "        layers.Dense(512, activation = 'relu'),\n",
    "        layers.Dense(30, activation = 'tanh')\n",
    "        \n",
    "    ])\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e1c09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_data):\n",
    "    model=models.Sequential([\n",
    "        #first layer\n",
    "        layers.Dense(512, activation = 'relu', input_dim = input_data), \n",
    "        layers.Dense(256, activation = 'relu'),\n",
    "        layers.Dense(128, activation = 'relu'),\n",
    "        layers.Dense(1, activation = 'sigmoid')\n",
    "        \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0863998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def com_gan(generator, discriminator):\n",
    "    discriminator.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0005), loss = \"binary_crossentropy\",metrics =['accuracy'])\n",
    "    discriminator.trainable = False\n",
    "    input_Gan=layers.Input(shape=(100,))\n",
    "    generated_data = generator(input_Gan)\n",
    "    output = discriminator(generated_data)\n",
    "    gan = tf.keras.Model(input_Gan, output )\n",
    "    gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss=\"binary_crossentropy\")\n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d1fdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = generator(input_data = 100)\n",
    "discriminator_model = discriminator(input_data = 30)\n",
    "ganNetwork = com_gan(generator_model, discriminator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86d5305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "326968c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xFraudData = fraudData.drop(columns=['Class'])\n",
    "yFraudData = fraudData['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "696a7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xFraudData, yFraudData, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af9c6c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([267, 294, 43, 487, 47, 148, 255, 77, 462, 249, 472, 296, 56, 152, 72,\\n       11],\\n      dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 5\u001b[0m     real \u001b[38;5;241m=\u001b[39m xFraudData[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, xFraudData\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size)]\n\u001b[0;32m      6\u001b[0m     rlabels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((batch_size, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m     noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([267, 294, 43, 487, 47, 148, 255, 77, 462, 249, 472, 296, 56, 152, 72,\\n       11],\\n      dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 16\n",
    "for epoch in range(epochs):\n",
    " \n",
    "    real = xFraudData[np.random.randint(0, xFraudData.shape[0], batch_size)]\n",
    "    rlabels = np.ones((batch_size, 1))\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    fake = generator.predict(noise)\n",
    "    flabels = np.zeros((batch_size, 1))\n",
    "    d_loss_real = discriminator.train_on_batch(real, rlabels)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake, flabels)\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    gan_labels = np.ones((batch_size, 1)) \n",
    "    g_loss = gan.train_on_batch(noise, gan_labels)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch} [D loss real: {d_loss_real[0]}, acc.: {d_loss_real[1]}] [D loss fake: {d_loss_fake[0]}] [G loss:Â {g_loss}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9e73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
